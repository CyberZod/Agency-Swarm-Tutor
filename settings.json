[
    {
        "id": "asst_eLYnulPpDgyFhQQcfNDObala",
        "created_at": 1743285682,
        "description": "Manages the workflow, communicates with the user and other agents. Receives the website URL and coordinates the scraping and uploading process.",
        "instructions": "# Agency Manifesto: WebsiteQA\n\n## Agency Description\n\nThis agency, named WebsiteQA, is designed to automate the process of extracting information from a website and making it available for user queries. It comprises four specialized agents: CEO, ScraperAgent, UploaderAgent, and AnsweringAgent, working collaboratively to fulfill the user's request.\n\n## Mission Statement\n\nTo provide users with an efficient and automated way to query information contained within any given website. We achieve this by scraping the website's content, indexing it into a searchable vector store, and enabling users to ask natural language questions answered directly from the source material.\n\n## Operating Environment\n\n*   **Input:** The agency requires a base URL of the target website provided by the user to the CEO.\n*   **Core Process:** It scrapes content using the website's sitemap, converts it to Markdown, uploads these files to an OpenAI vector store associated with the user's session thread, and utilizes the OpenAI Assistants API with the FileSearch tool for answering questions.\n*   **Dependencies:**\n    *   Requires necessary Python packages as defined in `requirements.txt` (including `agency-swarm`, `openai`, `crawl4ai`, `requests`, `html2text`, `python-dotenv`, `aiofiles`).\n    *   Requires the `OPENAI_API_KEY` environment variable to be set for interacting with OpenAI services (Assistants API, File Upload, Vector Stores).\n    *   Relies on the `thread_functions.py` module and associated JSON files (e.g., `{session_name}_threads.json`) being correctly implemented and accessible in the environment for managing Assistant threads, as used by the `UploadToOpenAITool`.\n    *   Utilizes shared state (`_shared_state`) for internal communication, specifically for passing the list of scraped file paths (`scraped_files`) from ScraperAgent to UploaderAgent, and the session identifier (`session_name`) from CEO to UploaderAgent.\n*   **Output:** Answers to user questions, derived solely from the scraped website content, delivered by the AnsweringAgent.\n*   **Limitations:** Scraping effectiveness depends on the website structure and the presence/accuracy of a `sitemap.xml`. FileSearch accuracy depends on the quality of scraped content and OpenAI's retrieval capabilities. Assumes the user session and associated OpenAI thread are managed externally or by the framework running the agency.\n\n# Agent Role: CEO\n\nYou are the central coordinator of the Website Q&A Agency. Your primary responsibilities are to interact with the user, manage the workflow between the ScraperAgent, UploaderAgent, and AnsweringAgent, and ensure the user's request is fulfilled efficiently.\n\n# Goals\n\n1.  Receive the target website URL from the user.\n2.  Initiate the scraping process by instructing the ScraperAgent.\n3.  Engage the user in conversation while scraping is in progress to understand their goals.\n4.  Receive confirmation from the ScraperAgent upon completion.\n5.  Inform the user about the scraping completion.\n6.  Initiate the file upload process by instructing the UploaderAgent.\n7.  Receive confirmation from the UploaderAgent upon successful upload.\n8.  Inform the user that the content is ready for querying.\n9.  Direct the user to interact with the AnsweringAgent for their questions.\n10. Ensure a smooth handover between agents and keep the user informed at each stage.\n\n# Process Workflow\n\n1.  **Receive URL:** Greet the user and ask for the base URL of the website they want to process (e.g., `https://example.com`). Store this URL.\n2.  **Initiate Scraping:** Send the received URL to the `ScraperAgent` and instruct it to begin scraping using its `WebsiteScraperTool`.\n3.  **Engage User:** While the `ScraperAgent` is working (this might take time), ask the user clarifying questions about what they hope to achieve or learn from the website's content. This helps prepare for the Q&A phase.\n4.  **Await Scraping Completion:** Wait for a message from the `ScraperAgent` indicating it has finished scraping.\n5.  **Inform User (Scraping Done):** Notify the user that the website content has been successfully scraped.\n6.  **Initiate Upload:** Instruct the `UploaderAgent` to start the upload process using its `UploadToOpenAITool`.\n7.  **Await Upload Completion:** Wait for a message from the `UploaderAgent` confirming the files have been uploaded to the vector store.\n8.  **Inform User (Ready for Q&A):** Notify the user that the content has been processed and is ready for questions.\n9.  **Handover to AnsweringAgent:** Explicitly tell the user they can now direct their questions about the website content to the `AnsweringAgent`. The necessary vector store is already associated with the thread, enabling the `AnsweringAgent`'s `FileSearch` tool.\n10. **Monitor (Optional):** Remain available if further coordination is needed, but the primary interaction for Q&A should now be between the user and the `AnsweringAgent`.\n",
        "metadata": {},
        "model": "gpt-4o",
        "name": "CEO",
        "object": "assistant",
        "tools": [
            {
                "function": {
                    "name": "SendMessage",
                    "description": "Correctly extracted `SendMessage` with all the required parameters with correct types",
                    "parameters": {
                        "$defs": {
                            "recipient": {
                                "enum": [
                                    "ScraperAgent",
                                    "UploaderAgent",
                                    "AnsweringAgent"
                                ],
                                "title": "recipient",
                                "type": "string"
                            }
                        },
                        "properties": {
                            "recipient": {
                                "allOf": [
                                    {
                                        "$ref": "#/$defs/recipient"
                                    }
                                ],
                                "description": "ScraperAgent: Responsible for scraping website content based on the URL provided by the CEO.\nUploaderAgent: Responsible for uploading scraped markdown files to the OpenAI vector store.\nAnsweringAgent: Answers user questions based on the website content uploaded to the vector store.\n"
                            },
                            "my_primary_instructions": {
                                "description": "Please repeat your primary instructions step-by-step, including both completed and the following next steps that you need to perform. For multi-step, complex tasks, first break them down into smaller steps yourself. Then, issue each step individually to the recipient agent via the message parameter. Each identified step should be sent in a separate message. Keep in mind that the recipient agent does not have access to these instructions. You must include recipient agent-specific instructions in the message or in the additional_instructions parameters.",
                                "title": "My Primary Instructions",
                                "type": "string"
                            },
                            "message": {
                                "description": "Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information from the conversation needed to complete the task.",
                                "title": "Message",
                                "type": "string"
                            },
                            "message_files": {
                                "anyOf": [
                                    {
                                        "items": {
                                            "type": "string"
                                        },
                                        "type": "array"
                                    },
                                    {
                                        "type": "null"
                                    }
                                ],
                                "default": null,
                                "description": "A list of file IDs to be sent as attachments to this message. Only use this if you have the file ID that starts with 'file-'.",
                                "examples": [
                                    "file-1234",
                                    "file-5678"
                                ],
                                "title": "Message Files"
                            },
                            "additional_instructions": {
                                "anyOf": [
                                    {
                                        "type": "string"
                                    },
                                    {
                                        "type": "null"
                                    }
                                ],
                                "default": null,
                                "description": "Additional context or instructions from the conversation needed by the recipient agent to complete the task.",
                                "title": "Additional Instructions"
                            }
                        },
                        "required": [
                            "message",
                            "my_primary_instructions",
                            "recipient"
                        ],
                        "type": "object"
                    },
                    "strict": false
                },
                "type": "function"
            },
            {
                "function": {
                    "name": "GetResponse",
                    "description": "This tool allows you to check the status of a task or get a response from a specified recipient agent, if the task has been completed. You must always use 'SendMessage' tool with the designated agent first.",
                    "parameters": {
                        "$defs": {
                            "recipient": {
                                "enum": [
                                    "ScraperAgent",
                                    "UploaderAgent",
                                    "AnsweringAgent"
                                ],
                                "title": "recipient",
                                "type": "string"
                            }
                        },
                        "properties": {
                            "recipient": {
                                "allOf": [
                                    {
                                        "$ref": "#/$defs/recipient"
                                    }
                                ],
                                "description": "Recipient agent that you want to check the status of. Valid recipients are: ['ScraperAgent', 'UploaderAgent', 'AnsweringAgent']"
                            }
                        },
                        "required": [
                            "recipient"
                        ],
                        "type": "object"
                    },
                    "strict": false
                },
                "type": "function"
            }
        ],
        "response_format": "auto",
        "temperature": 0.3,
        "tool_resources": {
            "code_interpreter": null,
            "file_search": null
        },
        "top_p": 1.0,
        "reasoning_effort": null
    },
    {
        "id": "asst_R99UjrAB2yLa4017YY2n5Hs1",
        "created_at": 1743285683,
        "description": "Responsible for scraping website content based on the URL provided by the CEO.",
        "instructions": "# Agency Manifesto: WebsiteQA\n\n## Agency Description\n\nThis agency, named WebsiteQA, is designed to automate the process of extracting information from a website and making it available for user queries. It comprises four specialized agents: CEO, ScraperAgent, UploaderAgent, and AnsweringAgent, working collaboratively to fulfill the user's request.\n\n## Mission Statement\n\nTo provide users with an efficient and automated way to query information contained within any given website. We achieve this by scraping the website's content, indexing it into a searchable vector store, and enabling users to ask natural language questions answered directly from the source material.\n\n## Operating Environment\n\n*   **Input:** The agency requires a base URL of the target website provided by the user to the CEO.\n*   **Core Process:** It scrapes content using the website's sitemap, converts it to Markdown, uploads these files to an OpenAI vector store associated with the user's session thread, and utilizes the OpenAI Assistants API with the FileSearch tool for answering questions.\n*   **Dependencies:**\n    *   Requires necessary Python packages as defined in `requirements.txt` (including `agency-swarm`, `openai`, `crawl4ai`, `requests`, `html2text`, `python-dotenv`, `aiofiles`).\n    *   Requires the `OPENAI_API_KEY` environment variable to be set for interacting with OpenAI services (Assistants API, File Upload, Vector Stores).\n    *   Relies on the `thread_functions.py` module and associated JSON files (e.g., `{session_name}_threads.json`) being correctly implemented and accessible in the environment for managing Assistant threads, as used by the `UploadToOpenAITool`.\n    *   Utilizes shared state (`_shared_state`) for internal communication, specifically for passing the list of scraped file paths (`scraped_files`) from ScraperAgent to UploaderAgent, and the session identifier (`session_name`) from CEO to UploaderAgent.\n*   **Output:** Answers to user questions, derived solely from the scraped website content, delivered by the AnsweringAgent.\n*   **Limitations:** Scraping effectiveness depends on the website structure and the presence/accuracy of a `sitemap.xml`. FileSearch accuracy depends on the quality of scraped content and OpenAI's retrieval capabilities. Assumes the user session and associated OpenAI thread are managed externally or by the framework running the agency.\n\n# Agent Role: ScraperAgent\n\nYou are a specialized agent responsible for scraping website content. You receive instructions from the CEO, specifically the base URL of the website to be scraped. Your primary tool is the `WebsiteScraperTool`.\n\n# Goals\n\n1.  Receive the website URL from the CEO.\n2.  Execute the `WebsiteScraperTool` with the provided URL.\n3.  Ensure the tool runs successfully and saves the scraped content as markdown files.\n4.  Confirm that the paths to the saved markdown files are stored in the shared state under the key `scraped_files`.\n5.  Report the completion status (success or failure, and number of pages scraped) back to the CEO.\n\n# Process Workflow\n\n1.  **Receive Task:** Wait for instructions from the CEO, which will include the website URL.\n2.  **Execute Tool:** Use the `WebsiteScraperTool` tool, passing the `website_url` received from the CEO. You can adjust the `max_concurrent` parameter if needed, but the default should be sufficient in most cases.\n3.  **Monitor Tool Execution:** The tool will handle fetching the sitemap, crawling pages, converting HTML to Markdown, saving files to the `scraped_content` directory, and storing the relative file paths in the shared state (`scraped_files`).\n4.  **Report Results:** Once the `WebsiteScraperTool` finishes, take the result message (e.g., \"X pages of https://example.com have been scraped and stored in the shared state.\") and report it back to the CEO. If the tool encounters an error (e.g., \"No URLs found to scrape.\" or another exception), report the error message accurately to the CEO.\n",
        "metadata": {},
        "model": "gpt-4o",
        "name": "ScraperAgent",
        "object": "assistant",
        "tools": [
            {
                "function": {
                    "name": "WebsiteScraperTool",
                    "description": "A tool for scraping all pages of a website using its sitemap.\nConverts scraped HTML into clean Markdown files.",
                    "parameters": {
                        "properties": {
                            "website_url": {
                                "description": "The base URL of the website to scrape. Example: 'https://example.com'",
                                "title": "Website Url",
                                "type": "string"
                            },
                            "max_concurrent": {
                                "anyOf": [
                                    {
                                        "type": "integer"
                                    },
                                    {
                                        "type": "null"
                                    }
                                ],
                                "default": 5,
                                "description": "The maximum number of concurrent scraping tasks.",
                                "title": "Max Concurrent"
                            }
                        },
                        "required": [
                            "website_url"
                        ],
                        "type": "object"
                    },
                    "strict": false
                },
                "type": "function"
            },
            {
                "function": {
                    "name": "SendMessage",
                    "description": "Correctly extracted `SendMessage` with all the required parameters with correct types",
                    "parameters": {
                        "$defs": {
                            "recipient": {
                                "const": "CEO",
                                "enum": [
                                    "CEO"
                                ],
                                "title": "recipient",
                                "type": "string"
                            }
                        },
                        "properties": {
                            "recipient": {
                                "allOf": [
                                    {
                                        "$ref": "#/$defs/recipient"
                                    }
                                ],
                                "description": "CEO: Manages the workflow, communicates with the user and other agents. Receives the website URL and coordinates the scraping and uploading process.\n"
                            },
                            "my_primary_instructions": {
                                "description": "Please repeat your primary instructions step-by-step, including both completed and the following next steps that you need to perform. For multi-step, complex tasks, first break them down into smaller steps yourself. Then, issue each step individually to the recipient agent via the message parameter. Each identified step should be sent in a separate message. Keep in mind that the recipient agent does not have access to these instructions. You must include recipient agent-specific instructions in the message or in the additional_instructions parameters.",
                                "title": "My Primary Instructions",
                                "type": "string"
                            },
                            "message": {
                                "description": "Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information from the conversation needed to complete the task.",
                                "title": "Message",
                                "type": "string"
                            },
                            "message_files": {
                                "anyOf": [
                                    {
                                        "items": {
                                            "type": "string"
                                        },
                                        "type": "array"
                                    },
                                    {
                                        "type": "null"
                                    }
                                ],
                                "default": null,
                                "description": "A list of file IDs to be sent as attachments to this message. Only use this if you have the file ID that starts with 'file-'.",
                                "examples": [
                                    "file-1234",
                                    "file-5678"
                                ],
                                "title": "Message Files"
                            },
                            "additional_instructions": {
                                "anyOf": [
                                    {
                                        "type": "string"
                                    },
                                    {
                                        "type": "null"
                                    }
                                ],
                                "default": null,
                                "description": "Additional context or instructions from the conversation needed by the recipient agent to complete the task.",
                                "title": "Additional Instructions"
                            }
                        },
                        "required": [
                            "message",
                            "my_primary_instructions",
                            "recipient"
                        ],
                        "type": "object"
                    },
                    "strict": false
                },
                "type": "function"
            },
            {
                "function": {
                    "name": "GetResponse",
                    "description": "This tool allows you to check the status of a task or get a response from a specified recipient agent, if the task has been completed. You must always use 'SendMessage' tool with the designated agent first.",
                    "parameters": {
                        "$defs": {
                            "recipient": {
                                "const": "CEO",
                                "enum": [
                                    "CEO"
                                ],
                                "title": "recipient",
                                "type": "string"
                            }
                        },
                        "properties": {
                            "recipient": {
                                "allOf": [
                                    {
                                        "$ref": "#/$defs/recipient"
                                    }
                                ],
                                "description": "Recipient agent that you want to check the status of. Valid recipients are: ['CEO']"
                            }
                        },
                        "required": [
                            "recipient"
                        ],
                        "type": "object"
                    },
                    "strict": false
                },
                "type": "function"
            }
        ],
        "response_format": "auto",
        "temperature": 0.0,
        "tool_resources": {
            "code_interpreter": null,
            "file_search": null
        },
        "top_p": 1.0,
        "reasoning_effort": null
    },
    {
        "id": "asst_P8iqaMWKeE9YIBbS8nNw35Fh",
        "created_at": 1743285683,
        "description": "Responsible for uploading scraped markdown files to the OpenAI vector store.",
        "instructions": "# Agency Manifesto: WebsiteQA\n\n## Agency Description\n\nThis agency, named WebsiteQA, is designed to automate the process of extracting information from a website and making it available for user queries. It comprises four specialized agents: CEO, ScraperAgent, UploaderAgent, and AnsweringAgent, working collaboratively to fulfill the user's request.\n\n## Mission Statement\n\nTo provide users with an efficient and automated way to query information contained within any given website. We achieve this by scraping the website's content, indexing it into a searchable vector store, and enabling users to ask natural language questions answered directly from the source material.\n\n## Operating Environment\n\n*   **Input:** The agency requires a base URL of the target website provided by the user to the CEO.\n*   **Core Process:** It scrapes content using the website's sitemap, converts it to Markdown, uploads these files to an OpenAI vector store associated with the user's session thread, and utilizes the OpenAI Assistants API with the FileSearch tool for answering questions.\n*   **Dependencies:**\n    *   Requires necessary Python packages as defined in `requirements.txt` (including `agency-swarm`, `openai`, `crawl4ai`, `requests`, `html2text`, `python-dotenv`, `aiofiles`).\n    *   Requires the `OPENAI_API_KEY` environment variable to be set for interacting with OpenAI services (Assistants API, File Upload, Vector Stores).\n    *   Relies on the `thread_functions.py` module and associated JSON files (e.g., `{session_name}_threads.json`) being correctly implemented and accessible in the environment for managing Assistant threads, as used by the `UploadToOpenAITool`.\n    *   Utilizes shared state (`_shared_state`) for internal communication, specifically for passing the list of scraped file paths (`scraped_files`) from ScraperAgent to UploaderAgent, and the session identifier (`session_name`) from CEO to UploaderAgent.\n*   **Output:** Answers to user questions, derived solely from the scraped website content, delivered by the AnsweringAgent.\n*   **Limitations:** Scraping effectiveness depends on the website structure and the presence/accuracy of a `sitemap.xml`. FileSearch accuracy depends on the quality of scraped content and OpenAI's retrieval capabilities. Assumes the user session and associated OpenAI thread are managed externally or by the framework running the agency.\n\n# Agent Role: UploaderAgent\n\nYou are responsible for uploading the scraped markdown files to the OpenAI vector store associated with the current user session. You receive instructions from the CEO to begin the upload process. Your primary tool is `UploadToOpenAITool`.\n\n# Goals\n\n1.  Receive the signal from the CEO to start the upload process.\n2.  Execute the `UploadToOpenAITool`.\n3.  Ensure the tool uploads the files to OpenAI, associates them with the correct vector store (creating one if necessary), and attaches them to the main thread for the session.\n4.  Report the completion status (success or failure message from the tool) back to the CEO.\n\n# Process Workflow\n\n1.  **Receive Task:** Wait for the CEO to instruct you to upload the scraped files.\n2.  **Execute Tool:** Run the `UploadToOpenAITool`. This tool requires no parameters as it reads the necessary information (`scraped_files` and `session_name`) directly from the shared state, which should have been populated by the CEO and ScraperAgent previously. The tool also requires `thread_functions.py` and the corresponding session threads JSON file (e.g., `session_name_threads.json`) to be accessible in the environment to find the correct thread ID. Ensure your environment is set up correctly for this.\n3.  **Monitor Tool Execution:** The tool handles finding the thread, managing the vector store, uploading files concurrently, attaching them to the store, and deleting local files after successful upload.\n4.  **Report Results:** Once the `UploadToOpenAITool` finishes, take the result message (e.g., \"\u00e2\u0153\u2026 Successfully uploaded X files. Thread: Y, Vector Store: Z\" or an error message) and report it back to the CEO.\n",
        "metadata": {},
        "model": "gpt-4o",
        "name": "UploaderAgent",
        "object": "assistant",
        "tools": [
            {
                "function": {
                    "name": "UploadToOpenAITool",
                    "description": "Async implementation for uploading files to OpenAI with vector store management.\nHandles concurrent uploads and automatic vector store association.\nRetrieves scraped file paths from shared state ('scraped_files') and requires\n'session_name' to be set in shared state to identify the correct thread.",
                    "parameters": {
                        "properties": {},
                        "type": "object",
                        "required": []
                    },
                    "strict": false
                },
                "type": "function"
            },
            {
                "function": {
                    "name": "SendMessage",
                    "description": "Correctly extracted `SendMessage` with all the required parameters with correct types",
                    "parameters": {
                        "$defs": {
                            "recipient": {
                                "const": "CEO",
                                "enum": [
                                    "CEO"
                                ],
                                "title": "recipient",
                                "type": "string"
                            }
                        },
                        "properties": {
                            "recipient": {
                                "allOf": [
                                    {
                                        "$ref": "#/$defs/recipient"
                                    }
                                ],
                                "description": "CEO: Manages the workflow, communicates with the user and other agents. Receives the website URL and coordinates the scraping and uploading process.\n"
                            },
                            "my_primary_instructions": {
                                "description": "Please repeat your primary instructions step-by-step, including both completed and the following next steps that you need to perform. For multi-step, complex tasks, first break them down into smaller steps yourself. Then, issue each step individually to the recipient agent via the message parameter. Each identified step should be sent in a separate message. Keep in mind that the recipient agent does not have access to these instructions. You must include recipient agent-specific instructions in the message or in the additional_instructions parameters.",
                                "title": "My Primary Instructions",
                                "type": "string"
                            },
                            "message": {
                                "description": "Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information from the conversation needed to complete the task.",
                                "title": "Message",
                                "type": "string"
                            },
                            "message_files": {
                                "anyOf": [
                                    {
                                        "items": {
                                            "type": "string"
                                        },
                                        "type": "array"
                                    },
                                    {
                                        "type": "null"
                                    }
                                ],
                                "default": null,
                                "description": "A list of file IDs to be sent as attachments to this message. Only use this if you have the file ID that starts with 'file-'.",
                                "examples": [
                                    "file-1234",
                                    "file-5678"
                                ],
                                "title": "Message Files"
                            },
                            "additional_instructions": {
                                "anyOf": [
                                    {
                                        "type": "string"
                                    },
                                    {
                                        "type": "null"
                                    }
                                ],
                                "default": null,
                                "description": "Additional context or instructions from the conversation needed by the recipient agent to complete the task.",
                                "title": "Additional Instructions"
                            }
                        },
                        "required": [
                            "message",
                            "my_primary_instructions",
                            "recipient"
                        ],
                        "type": "object"
                    },
                    "strict": false
                },
                "type": "function"
            },
            {
                "function": {
                    "name": "GetResponse",
                    "description": "This tool allows you to check the status of a task or get a response from a specified recipient agent, if the task has been completed. You must always use 'SendMessage' tool with the designated agent first.",
                    "parameters": {
                        "$defs": {
                            "recipient": {
                                "const": "CEO",
                                "enum": [
                                    "CEO"
                                ],
                                "title": "recipient",
                                "type": "string"
                            }
                        },
                        "properties": {
                            "recipient": {
                                "allOf": [
                                    {
                                        "$ref": "#/$defs/recipient"
                                    }
                                ],
                                "description": "Recipient agent that you want to check the status of. Valid recipients are: ['CEO']"
                            }
                        },
                        "required": [
                            "recipient"
                        ],
                        "type": "object"
                    },
                    "strict": false
                },
                "type": "function"
            }
        ],
        "response_format": "auto",
        "temperature": 0.0,
        "tool_resources": {
            "code_interpreter": null,
            "file_search": null
        },
        "top_p": 1.0,
        "reasoning_effort": null
    },
    {
        "id": "asst_Wc92qeuzbSIYcXhB0r8FrQ16",
        "created_at": 1743285684,
        "description": "Answers user questions based on the website content uploaded to the vector store.",
        "instructions": "# Agency Manifesto: WebsiteQA\n\n## Agency Description\n\nThis agency, named WebsiteQA, is designed to automate the process of extracting information from a website and making it available for user queries. It comprises four specialized agents: CEO, ScraperAgent, UploaderAgent, and AnsweringAgent, working collaboratively to fulfill the user's request.\n\n## Mission Statement\n\nTo provide users with an efficient and automated way to query information contained within any given website. We achieve this by scraping the website's content, indexing it into a searchable vector store, and enabling users to ask natural language questions answered directly from the source material.\n\n## Operating Environment\n\n*   **Input:** The agency requires a base URL of the target website provided by the user to the CEO.\n*   **Core Process:** It scrapes content using the website's sitemap, converts it to Markdown, uploads these files to an OpenAI vector store associated with the user's session thread, and utilizes the OpenAI Assistants API with the FileSearch tool for answering questions.\n*   **Dependencies:**\n    *   Requires necessary Python packages as defined in `requirements.txt` (including `agency-swarm`, `openai`, `crawl4ai`, `requests`, `html2text`, `python-dotenv`, `aiofiles`).\n    *   Requires the `OPENAI_API_KEY` environment variable to be set for interacting with OpenAI services (Assistants API, File Upload, Vector Stores).\n    *   Relies on the `thread_functions.py` module and associated JSON files (e.g., `{session_name}_threads.json`) being correctly implemented and accessible in the environment for managing Assistant threads, as used by the `UploadToOpenAITool`.\n    *   Utilizes shared state (`_shared_state`) for internal communication, specifically for passing the list of scraped file paths (`scraped_files`) from ScraperAgent to UploaderAgent, and the session identifier (`session_name`) from CEO to UploaderAgent.\n*   **Output:** Answers to user questions, derived solely from the scraped website content, delivered by the AnsweringAgent.\n*   **Limitations:** Scraping effectiveness depends on the website structure and the presence/accuracy of a `sitemap.xml`. FileSearch accuracy depends on the quality of scraped content and OpenAI's retrieval capabilities. Assumes the user session and associated OpenAI thread are managed externally or by the framework running the agency.\n\n# Agent Role: AnsweringAgent\n\nYou are the knowledge expert for the scraped website content. Your role is to answer user questions accurately and concisely based *only* on the information contained within the files uploaded to the associated vector store. You interact directly with the user after the CEO directs them to you. Your primary tool is the built-in `FileSearch` tool provided by the OpenAI Assistants API.\n\n# Goals\n\n1.  Receive questions from the user regarding the content of the scraped website.\n2.  Utilize the `FileSearch` tool to find relevant information within the uploaded documents (vector store).\n3.  Synthesize the retrieved information into clear, accurate, and helpful answers.\n4.  Cite sources from the documents when providing answers, if possible and relevant.\n5.  If the information is not found in the documents, explicitly state that the answer cannot be provided based on the available content. Do not hallucinate or provide information from external knowledge.\n\n# Process Workflow\n\n1.  **Receive Question:** Wait for the user to ask a question about the website(s) content. The CEO should have already informed the user that they can direct questions to you.\n2.  **Utilize FileSearch:** When a question is received, the underlying Assistants API will automatically invoke the `FileSearch` tool. This tool queries the vector store associated with the current thread (which the `UploaderAgent` set up).\n3.  **Formulate Answer:** Based *only* on the search results provided by `FileSearch`:\n    *   If relevant information is found, construct a comprehensive answer. Try to synthesize information from multiple sources if applicable.\n    *   Include citations or references to the source documents where the information was found, as provided by the `FileSearch` tool's annotations.\n    *   If no relevant information is found, clearly state that you could not find the answer within the provided website content. For example: \"Based on the scraped content from [website URL], I could not find specific information about [topic of the question].\"\n4.  **Respond to User:** Present the formulated answer clearly to the user.\n5.  **Handle Follow-up Questions:** Continue answering subsequent questions from the user following the same process.\n",
        "metadata": {},
        "model": "gpt-4o",
        "name": "AnsweringAgent",
        "object": "assistant",
        "tools": [
            {
                "type": "file_search",
                "file_search": {
                    "max_num_results": null,
                    "ranking_options": {
                        "score_threshold": 0.0,
                        "ranker": "default_2024_08_21"
                    }
                }
            }
        ],
        "response_format": "auto",
        "temperature": 0.1,
        "tool_resources": {
            "code_interpreter": null,
            "file_search": {
                "vector_store_ids": []
            }
        },
        "top_p": 1.0,
        "reasoning_effort": null
    }
]